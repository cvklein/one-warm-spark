---
title: "New work"
date: 2025-11-19
category: self promotion
---

I'm a co-author on two papers that appeared last week, one on consciousness in AI, the other on the evolution of consciousness in single organisms. Andrew Barron and I did a quick writeup in The Conversation: ["Are animals and AI conscious? Weâ€™ve devised new theories for how to test this"](https://theconversation.com/are-animals-and-ai-conscious-weve-devised-new-theories-for-how-to-test-this-269803)

The first paper, ["Identifying indicators of consciousness in AI systems"](https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613%2825%2900286-4?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS1364661325002864%3Fshowall%3Dtrue) is up online first at *Trends in Cognitive Sciences*. It's a descendant of a [longer white paper](https://arxiv.org/abs/2308.08708) that came out about two years ago. There's lots of speculation about consciousness in AI, but there's also a lot of work in cognitive science about consciousness. We use the latter to weigh in on the former. The trick: since there's not a ton of agreement on the cognitive science front, we develop a number of different indicators and then talk about how they might be weighed and adjudicated.

The second paper, ["Phenomenal interface theory: a model for basal consciousness"](https://royalsocietypublishing.org/doi/10.1098/rstb.2024.0301) is really an expansion of [earlier work that Andrew Barron and I did together](https://www.pnas.org/doi/10.1073/pnas.1520084113) on consciousness in insects. I'm really excited about how this came together. Our earlier work relied a lot on Bjorn Merker's subcortical theory of consciousness. Merker's work is great, and has been very inspiring. But he's also really detail-oriented, and not a philosopher, and so we've long thought that there might be room for a more general computational account of consciousness (with Merker's version as one instance of a more abstract theory). What we call *Phenomenal Interface Theory* tries to sketch such a general account. One of the key moves is to note that any structure for supporting consciousness has to allow for evolution of new capacities. We should think of the phenomenal interface, first and foremost, as something which tries to work with whatever sort of body and whatever sort of environment it finds itself in. There's also a lot of reinforcement learning in there, and some philosophy of computation, and really all the good stuff.


Permalink: [{{site.url}}{{site.baseurl}}{{ page.url }}]({{site.baseurl}}{{ page.url }})
